{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "                                    tokenized_review  label  \\\n",
      "0  ['bromwell', 'high', 'cartoon', 'comedy', 'ran...      1   \n",
      "1  ['homelessness', 'houselessness', 'george', 'c...      1   \n",
      "2  ['brilliant', 'overacting', 'lesley', 'ann', '...      1   \n",
      "3  ['easily', 'underrated', 'film', 'inn', 'brook...      1   \n",
      "4  ['typical', 'mel', 'brooks', 'film', 'slapstic...      1   \n",
      "\n",
      "                                       padded_review  \n",
      "0  [1, 7323, 2274, 2956, 12444, 15823, 12104, 136...  \n",
      "1  [1, 1, 6465, 1, 14855, 8270, 17417, 11633, 724...  \n",
      "2  [1864, 11048, 1, 580, 16961, 1411, 4634, 1, 87...  \n",
      "3  [4836, 16350, 5810, 7999, 1904, 2164, 15282, 5...  \n",
      "4  [16264, 9793, 1904, 5810, 14290, 10269, 151, 1...  \n",
      "\n",
      "Test Data:\n",
      "                                    tokenized_review  label  \\\n",
      "0  ['went', 'saw', 'movie', 'night', 'coaxed', 'f...      1   \n",
      "1  ['actor', 'turned', 'director', 'bill', 'paxto...      1   \n",
      "2  ['recreational', 'golfer', 'knowledge', 'sport...      1   \n",
      "3  ['saw', 'film', 'sneak', 'preview', 'delightfu...      1   \n",
      "4  ['bill', 'paxton', 'taken', 'true', 'story', '...      1   \n",
      "\n",
      "                                       padded_review  \n",
      "0  [17092, 13543, 10254, 10578, 1, 6229, 7697, 20...  \n",
      "1  [142, 16226, 4329, 1472, 11336, 6038, 12129, 3...  \n",
      "2  [1, 1, 8707, 14724, 7388, 11674, 4418, 13818, ...  \n",
      "3  [13543, 5810, 14422, 12006, 4014, 2686, 16536,...  \n",
      "4  [1472, 11336, 15452, 16176, 14975, 6631, 10898...  \n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import pandas as pd \n",
    "# Load preprocessed data\n",
    "train_df = pd.read_csv(\"train_data_final_2.csv\")\n",
    "test_df = pd.read_csv(\"test_data_final_2.csv\")\n",
    "\n",
    "# %%\n",
    "# Inspect the first few rows\n",
    "print(\"Training Data:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in training loader: 45\n",
      "Number of batches in dev loader: 5\n",
      "Number of batches in test loader: 25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import ast  # For safely evaluating strings containing Python literals\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "\n",
    "vocab_size = 17502  # Size of the vocabulary\n",
    "vocab_size = min(vocab_size, 10000)  # Reduce vocab size to 15,000\n",
    "\n",
    "\n",
    "def index_to_one_hot(index, vocab_size):\n",
    "    \"\"\" Convert an index to a one-hot encoded vector \"\"\"\n",
    "    one_hot = torch.zeros(vocab_size)\n",
    "    one_hot[index] = 1\n",
    "    return one_hot\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): Dataframe containing 'padded_review' and 'label'.\n",
    "        \"\"\"\n",
    "        self.reviews = dataframe['padded_review']\n",
    "        self.labels = dataframe['label']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        indices = self.reviews.iloc[idx]\n",
    "        # Ensure indices are within the vocab_size range by clamping\n",
    "        indices = [min(index, vocab_size - 1) for index in indices]\n",
    "        one_hot_encoded = torch.stack([index_to_one_hot(index, vocab_size) for index in indices])\n",
    "        return one_hot_encoded, self.labels.iloc[idx]\n",
    "\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('train_data_final.csv')\n",
    "train_df = train_df.sample(n=400, random_state=42)  # Sampling 1000 examples due to dataset size\n",
    "\n",
    "test_df = pd.read_csv('train_data_final.csv')\n",
    "test_df = test_df.sample(n=200, random_state=42)  # Sampling 1000 examples due to dataset size\n",
    "\n",
    "\n",
    "# Splitting data into train, dev, and test sets\n",
    "# train_data, test_data = train_test_split(test_df, test_size=0.2, random_state=42)\n",
    "train_data, dev_data = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "test_data = test_df\n",
    "\n",
    "# Truncate the sequences to max_length within the DataFrame\n",
    "max_length = 105  \n",
    "\n",
    "# Apply truncation directly to the 'padded_review' column in each DataFrame\n",
    "train_df['padded_review'] = train_df['padded_review'].apply(lambda review: ast.literal_eval(review)[:max_length])\n",
    "dev_df = train_df.sample(frac=0.1, random_state=42)  # Extracting dev data from train_df\n",
    "train_df = train_df.drop(dev_df.index)  # Remaining for training\n",
    "test_df['padded_review'] = test_df['padded_review'].apply(lambda review: ast.literal_eval(review)[:max_length])\n",
    "\n",
    "# Ensure labels are numeric (convert if necessary)\n",
    "train_df['label'] = pd.to_numeric(train_df['label'])\n",
    "dev_df['label'] = pd.to_numeric(dev_df['label'])\n",
    "test_df['label'] = pd.to_numeric(test_df['label'])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SentimentDataset(train_df)\n",
    "dev_dataset = SentimentDataset(dev_df)\n",
    "test_dataset = SentimentDataset(test_df)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Print data loader counts\n",
    "print(f\"Number of batches in training loader: {len(train_loader)}\")\n",
    "print(f\"Number of batches in dev loader: {len(dev_loader)}\")\n",
    "print(f\"Number of batches in test loader: {len(test_loader)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch X shape: torch.Size([8, 105, 10000])\n",
      "Batch Y shape: torch.Size([8])\n",
      "Batch X content:\n",
      " tensor([[[0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         ...,\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        [[0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         ...,\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        [[0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         ...,\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.]]])\n",
      "Batch Y content: tensor([1, 1, 1, 1, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Print a dataloader batch\n",
    "for X_batch, y_batch in train_loader:\n",
    "    print(\"Batch X shape:\", X_batch.shape)  # Shape of the batch\n",
    "    print(\"Batch Y shape:\", y_batch.shape)  # Shape of the labels\n",
    "    print(\"Batch X content:\\n\", X_batch)    # Content of one-hot encoded vectors\n",
    "    print(\"Batch Y content:\", y_batch)      # Content of labels\n",
    "    break  # Break after printing the first batch to avoid printing multiple batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import copy\n",
    "\n",
    "\n",
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden1_size, hidden2_size, output_size):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden1_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden1_size, hidden2_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.output = nn.Linear(hidden2_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()  # For binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, 100, 2000]\n",
    "        # Flatten the input if necessary\n",
    "        x = x.view(x.size(0), -1)  # [batch_size, 100*2000] = [batch_size, 200000]\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.output(out)\n",
    "        out = self.sigmoid(out).squeeze()\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "input_size = 105 * 10000\n",
    "hidden1_size = 256\n",
    "hidden2_size = 128\n",
    "output_size = 1  # Binary classification\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Initialize the model\n",
    "model = FeedForwardNN(input_size, hidden1_size, hidden2_size, output_size)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Epoch [1/10], Loss: 0.6950, Dev Accuracy: 0.4750\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Epoch [2/10], Loss: 0.6721, Dev Accuracy: 0.5250\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Epoch [3/10], Loss: 0.6108, Dev Accuracy: 0.5250\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33120\\2446966517.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_Y\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mbatch_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mbatch_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_Y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Here\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_dev_accuracy = 0.0\n",
    "best_model_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_X, batch_Y in train_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_Y = batch_Y.to(device).float()\n",
    "        print(\"Here\")\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_Y)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * batch_X.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    # Evaluation on development set\n",
    "    model.eval()\n",
    "    dev_preds = []\n",
    "    dev_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_Y in dev_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_Y = batch_Y.to(device).float()\n",
    "            outputs = model(batch_X)\n",
    "            preds = (outputs >= 0.5).long()\n",
    "            dev_preds.extend(preds.cpu().numpy())\n",
    "            dev_labels.extend(batch_Y.cpu().numpy())\n",
    "\n",
    "    dev_accuracy = accuracy_score(dev_labels, dev_preds)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Dev Accuracy: {dev_accuracy:.4f}\")\n",
    "\n",
    "    # Save the model if dev accuracy improves\n",
    "    if dev_accuracy > best_dev_accuracy:\n",
    "        best_dev_accuracy = dev_accuracy\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(best_model_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6500\n",
      "Test Precision: 0.6923\n",
      "Test Recall: 0.6000\n",
      "Test F1-Score: 0.6429\n",
      "\n",
      "Per Class Metrics:\n",
      "Class 0 - Precision: 0.6147, Recall: 0.7053, F1-Score: 0.6569\n",
      "Class 1 - Precision: 0.6923, Recall: 0.6000, F1-Score: 0.6429\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_Y in test_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_Y = batch_Y.to(device).float()\n",
    "        outputs = model(batch_X)\n",
    "        preds = (outputs >= 0.5).long()\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "        test_labels.extend(batch_Y.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(test_labels, test_preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(test_labels, test_preds, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Detailed metrics for each class\n",
    "precision_per_class, recall_per_class, f1_per_class, _ = precision_recall_fscore_support(\n",
    "    test_labels, test_preds, labels=[0,1]\n",
    ")\n",
    "\n",
    "print(\"\\nPer Class Metrics:\")\n",
    "print(f\"Class 0 - Precision: {precision_per_class[0]:.4f}, Recall: {recall_per_class[0]:.4f}, F1-Score: {f1_per_class[0]:.4f}\")\n",
    "print(f\"Class 1 - Precision: {precision_per_class[1]:.4f}, Recall: {recall_per_class[1]:.4f}, F1-Score: {f1_per_class[1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved to best_ffn_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Define the checkpoint path\n",
    "checkpoint_path = 'best_ffn_model.pth'\n",
    "\n",
    "# Save the best model\n",
    "torch.save(best_model_state, checkpoint_path)\n",
    "print(f\"Best model saved to {checkpoint_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
